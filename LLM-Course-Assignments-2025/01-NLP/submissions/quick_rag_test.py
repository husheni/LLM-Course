#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€ŸRAGæµ‹è¯• - éªŒè¯ä¼˜åŒ–æ•ˆæœ
"""

import json
import os
import time
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
import re

@dataclass
class RetrievalConfig:
    """æ£€ç´¢é…ç½®ç±»"""
    title_weight: float = 0.6
    question_weight: float = 0.4
    answer_weight: float = 0.0
    
    def normalize_weights(self):
        """æ ‡å‡†åŒ–æƒé‡"""
        total = self.title_weight + self.question_weight + self.answer_weight
        if total > 0:
            self.title_weight /= total
            self.question_weight /= total
            self.answer_weight /= total

class QuickRAGSystem:
    """å¿«é€ŸRAGç³»ç»Ÿ - æè‡´ä¼˜åŒ–ç‰ˆæœ¬"""
    
    def __init__(self, max_records: int = 5000):
        """
        åˆå§‹åŒ–å¿«é€ŸRAGç³»ç»Ÿ
        """
        self.max_records = max_records
        self.retrieval_config = RetrievalConfig()
        self.retrieval_config.normalize_weights()
        self.data_records = []
        
    def _build_simple_index(self, text: str) -> set:
        """æ„å»ºç®€å•æ–‡æœ¬ç´¢å¼•"""
        if not text:
            return set()
        words = re.findall(r'\b\w+\b', text.lower())
        return set(words)
    
    def _fast_similarity(self, index1: set, index2: set) -> float:
        """å¿«é€Ÿç›¸ä¼¼åº¦è®¡ç®—"""
        if not index1 and not index2:
            return 1.0
        if not index1 or not index2:
            return 0.0
        
        intersection = len(index1.intersection(index2))
        union = len(index1.union(index2))
        return intersection / union if union > 0 else 0.0
    
    def load_and_process_data(self, data_path: str) -> bool:
        """å¿«é€Ÿæ•°æ®åŠ è½½"""
        try:
            print(f"ğŸš€ å¿«é€ŸåŠ è½½æ•°æ®ï¼ˆé™åˆ¶ {self.max_records} æ¡ï¼‰...")
            
            with open(data_path, 'r', encoding='utf-8') as f:
                raw_data = json.load(f)
            
            # é™åˆ¶è®°å½•æ•°é‡
            raw_data = raw_data[:self.max_records]
            print(f"ğŸ“¥ åŠ è½½äº† {len(raw_data)} æ¡æ•°æ®")
            
            start_time = time.time()
            
            for i, item in enumerate(raw_data):
                record = {
                    'index': i,
                    'title': item.get('questionTitle', ''),
                    'question': item.get('questionText', ''),
                    'answer': item.get('answerText', ''),
                    'title_index': self._build_simple_index(item.get('questionTitle', '')),
                    'question_index': self._build_simple_index(item.get('questionText', '')),
                    'answer_index': self._build_simple_index(item.get('answerText', ''))
                }
                self.data_records.append(record)
                
                # æ˜¾ç¤ºè¿›åº¦
                if (i + 1) % 20 == 0:
                    progress = ((i + 1) / len(raw_data)) * 5000
                    elapsed = time.time() - start_time
                    print(f"âš¡ è¿›åº¦: {i+1}/{len(raw_data)} ({progress:.1f}%) - è€—æ—¶: {elapsed:.1f}s")
            
            load_time = time.time() - start_time
            print(f"âœ… æ•°æ®åŠ è½½å®Œæˆï¼å¤„ç†äº† {len(self.data_records)} æ¡è®°å½•ï¼Œè€—æ—¶: {load_time:.2f}ç§’")
            
            return True
            
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
    
    def search(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:
        """å¿«é€Ÿæœç´¢"""
        if not self.data_records:
            return []
        
        print(f"ğŸ” æœç´¢æŸ¥è¯¢: '{query}'")
        
        start_time = time.time()
        query_index = self._build_simple_index(query)
        
        results = []
        
        for record in self.data_records:
            # è®¡ç®—å„éƒ¨åˆ†ç›¸ä¼¼åº¦
            title_sim = self._fast_similarity(query_index, record['title_index'])
            question_sim = self._fast_similarity(query_index, record['question_index'])
            answer_sim = self._fast_similarity(query_index, record['answer_index'])
            
            # åŠ æƒè®¡ç®—æœ€ç»ˆç›¸ä¼¼åº¦
            final_sim = (
                self.retrieval_config.title_weight * title_sim +
                self.retrieval_config.question_weight * question_sim +
                self.retrieval_config.answer_weight * answer_sim
            )
            
            if final_sim > 0:
                results.append({
                    'record': record,
                    'similarity': final_sim,
                    'title_sim': title_sim,
                    'question_sim': question_sim,
                    'answer_sim': answer_sim
                })
        
        # æ’åºå¹¶è¿”å›å‰kä¸ª
        results.sort(key=lambda x: x['similarity'], reverse=True)
        results = results[:top_k]
        
        search_time = time.time() - start_time
        print(f"âš¡ æœç´¢å®Œæˆï¼è€—æ—¶: {search_time:.3f}ç§’ï¼Œæ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
        
        return results
    
    def generate_response(self, query: str, top_k: int = 3) -> str:
        """ç”Ÿæˆå›ç­”"""
        results = self.search(query, top_k)
        
        if not results:
            return "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ç»“æœã€‚"
        
        response = [f"åŸºäº {len(results)} ä¸ªç›¸å…³ç»“æœå›ç­” '{query}':\n"]
        
        for i, result in enumerate(results, 1):
            record = result['record']
            sim = result['similarity']
            
            response.append(f"**ç»“æœ {i}** (ç›¸ä¼¼åº¦: {sim:.3f})")
            response.append(f"é—®é¢˜: {record['title']}")
            if record['answer']:
                answer_preview = record['answer'][:150] + "..." if len(record['answer']) > 150 else record['answer']
                response.append(f"å›ç­”: {answer_preview}")
            response.append("")
        
        return "\n".join(response)


def quick_test():
    """å¿«é€Ÿæµ‹è¯•"""
    print("=" * 60)
    print("âš¡ å¿«é€ŸRAGç³»ç»Ÿæ€§èƒ½æµ‹è¯•")
    print("=" * 60)
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    rag = QuickRAGSystem(max_records=5000)  # åªæµ‹è¯•5000æ¡è®°å½•
    
    data_path = "e:/1__xubin_hu/Program and setting/datasets/Mental_Health_conv/cl_output_file.json"
    
    if not os.path.exists(data_path):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
        return
    
    # åŠ è½½æ•°æ®
    if not rag.load_and_process_data(data_path):
        return
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "panic attack symptoms",
        "anxiety treatment",
        "mental health types"
    ]
    
    print("\n" + "="*50)
    print("ğŸ” æœç´¢æµ‹è¯•")
    print("="*50)
    
    total_search_time = 0
    
    for query in test_queries:
        print(f"\n--- æŸ¥è¯¢: '{query}' ---")
        start_time = time.time()
        response = rag.generate_response(query, top_k=3)
        search_time = time.time() - start_time
        total_search_time += search_time
        
        print(response)
        print(f"â±ï¸  æœ¬æ¬¡æœç´¢è€—æ—¶: {search_time:.3f}ç§’")
        print("-" * 40)
    
    print(f"\nğŸ“Š æ€»æµ‹è¯•ç»Ÿè®¡:")
    print(f"  æ•°æ®è®°å½•æ•°: {len(rag.data_records)}")
    print(f"  å¹³å‡æœç´¢æ—¶é—´: {total_search_time/len(test_queries):.3f}ç§’")
    print(f"  æ€»æœç´¢æ—¶é—´: {total_search_time:.3f}ç§’")
    
    print("\nâœ… å¿«é€Ÿæµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    quick_test()